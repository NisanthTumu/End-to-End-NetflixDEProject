**Data Engineering Project**

The objective of this project is to build an end-to-end data engineering project with Azure services following medallion architecture, which involves data ingestion data factory pipelines with parameterization and using data bricks covering incremental loading using autoloader serving as bronze layer with unity catalog. Then silver layer contains the transformations using pyspark function and workflows activities in notebooks with dynamic capabilities for data enrichment. In gold layer, integrating delta live tables ETL workflow helps in serving the data warehouse for analytical reporting.

**Architecture Diagram:**

![ Diagram]( https://github.com/NisanthTumu/End-to-End-NetflixDEProject/blob/main/Architecture%20Diagram.jpg)

**ðŸŽ¯ Project Coverage:**

â€¢	Azure Data Architecture
â€¢	Data Understanding
â€¢	Azure Data Fundamentals
â€¢	Azure Data Factory 
â€¢	ETL Pipelines with Azure Data Factory
â€¢	Azure Data Factory Real Time Scenarios
â€¢	Databricks Unity Catalog
â€¢	Databricks Spark Cluster
â€¢	Incremental Loading in Databricks with Autoloader
â€¢	Spark Streaming
â€¢	Data Ingestion using PySpark
â€¢	Parameters using Databricks Utilities
â€¢	Data Orchestration with Databricks Workflows
â€¢	Pyspark Tutorial
â€¢	Data Transformation using PySpark
â€¢	Big Data Analytics with Apache Spark
â€¢	Databricks Delta Live Tables
â€¢	End to End Pipeline in Databricks

**âœ… Key Goals:**

â€¢ Automate Data Ingestion: Seamlessly ingest data from sources into ADLS Gen2 storage using Azure Data Factory and Databricks autoloader with parameters
â€¢ Implement Medallion Architecture: Organize and transform data through bronze, silver, and gold layers to improve data quality and accessibility.
â€¢ Enable Data Transformation & Enrichment: Leverage Azure Databricks for data processing with pyspark functions and work flows activities in dynamic notebooks
â€¢ Optimize Analytics : Using dimensional data modelling with star schema and delta live tables for efficient querying, analytics, and reporting on large datasets. 
â€¢ Create Interactive Visualizations: Build dynamic dashboards with Power BI/Tableau/Fabric to provide meaningful business insights. 
â€¢ Ensure Production-Readiness: Apply best practices for performance optimization, error handling, monitoring, and maintenance.
